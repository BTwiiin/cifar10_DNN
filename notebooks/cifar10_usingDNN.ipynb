{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Exploring Deep Neural Networks for CIFAR-10 Image Classification\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Deep Neural Networks (DNNs) have emerged as powerful tools for various machine learning tasks, particularly in the realm of image classification. In this Jupyter Notebook project, we embark on a journey into deep learning using TensorFlow to tackle one of the most iconic image classification benchmarks: the CIFAR-10 dataset.\n",
    "\n",
    "CIFAR-10 is a widely utilized benchmark dataset comprising 50,000 32x32 color images across 10 classes, with each class containing 5,000 images. The objective is to classify each image into one of the following categories: airplane, automobile, bird, cat, deer, dog, frog, horse, ship, and truck. While Convolutional Neural Networks (CNNs) are typically the architecture of choice for image classification tasks due to their spatial hierarchical learning capabilities, in this notebook, we will take a different approach. Instead of relying on CNNs, we will investigate the effectiveness of Deep Neural Networks (DNNs) in classifying CIFAR-10 images.\n",
    "\n",
    "The primary goal of this notebook is to showcase the potential of DNNs in handling image classification tasks even without convolutional layers. By constructing a DNN architecture from scratch using TensorFlow, we aim to gain insights into how DNNs perform on CIFAR-10 and explore their strengths and limitations compared to CNNs."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e4f361214999dad6"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-04-06T11:31:07.925740900Z",
     "start_time": "2024-04-06T11:31:07.142439700Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "(X_train_full, y_train_full), (X_test, y_test) = tf.keras.datasets.cifar10.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Establishing a Validation Set to Assess DNN Performance\n",
    "\n",
    "In order to gauge the performance of our Deep Neural Network (DNN), it's crucial to establish a validation set.\n",
    "I believe, that selecting 5000 samples from our dataset should suffice for this purpose."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "33c9772ba8a9db90"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "X_train = X_train_full[5000:]\n",
    "y_train = y_train_full[5000:]\n",
    "X_valid = X_train_full[:5000]\n",
    "y_valid = y_train_full[:5000]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-06T11:31:13.945240200Z",
     "start_time": "2024-04-06T11:31:13.886987Z"
    }
   },
   "id": "76efc7bf0c0651fb"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Creating a Sequential Model with TensorFlow API\n",
    "\n",
    "## DNN Architecture:\n",
    "\n",
    "- **Number of layers:** 5\n",
    "- **Number of neurons per layer:** 100\n",
    "- **Model type:** Sequential (no skip connections)\n",
    "\n",
    "## Hyperparameters:\n",
    "\n",
    "- **Activation Function:**\n",
    "  - Activation function: SELU (Scaled Exponential Linear Unit)\n",
    "    - Proven to self-normalize under certain conditions\n",
    "\n",
    "- **Weight Initialization:**\n",
    "  - Weight initialization: LeCun initialization\n",
    "    - Ensures effective learning dynamics\n",
    "\n",
    "- **Normalization Techniques:**\n",
    "  - Utilizing SELU activation eliminates the need for normalization techniques such as BatchNormalization or Dropout\n",
    "\n",
    "- **Input Standardization:**\n",
    "  - All inputs should be standardized before passing them to the DNN\n",
    "    - Ensures consistency and improves convergence\n",
    "\n",
    "- **Regularization Technique:**\n",
    "  - EarlyStopping regularization employed\n",
    "    - Utilizes a validation set to monitor loss convergence\n",
    "    - Allows for flexible control over the number of epochs\n",
    "\n",
    "- **Optimizer:**\n",
    "  - Optimizer: Nadam (Nesterov Adam)\n",
    "    - Known for its effectiveness in optimizing deep neural networks\n",
    "    - Combines momentum with the adaptive learning rate properties of Adam\n",
    "\n",
    "## Conditions for SELU to self-normalize:\n",
    "  - LeCun initialization\n",
    "  - Sequential architecture of model (no skip connections)\n",
    "  - Dense or convolutional layers\n",
    "  - Standardized inputs\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2caa6046cfca6841"
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [],
   "source": [
    "def create_model(n_layers=5, n_neurons=100, shape=[32, 32, 3]):\n",
    "    model = tf.keras.models.Sequential()\n",
    "\n",
    "    model.add(tf.keras.layers.Flatten(input_shape=shape))\n",
    "    for _ in range(n_layers):\n",
    "        model.add(tf.keras.layers.Dense(n_neurons,\n",
    "                                 activation=\"selu\",\n",
    "                                 kernel_initializer=\"lecun_normal\"))\n",
    "    model.add(tf.keras.layers.Dense(10, activation=\"softmax\"))\n",
    "\n",
    "    optimizer = tf.keras.optimizers.Nadam()\n",
    "    \n",
    "    model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=optimizer,\n",
    "              metrics=[\"accuracy\"])\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-05T11:57:07.442196800Z",
     "start_time": "2024-04-05T11:57:07.427190100Z"
    }
   },
   "id": "18bbcc2d3a5db2a1"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Parameter Tuning and TensorBoard Visualization\n",
    "\n",
    "Before training our model, one parameter we can tweak is the learning_rate of Nadam's optimizer. Adjusting this parameter can potentially lead to faster convergence and help avoid local optima. To aid us in this process, TensorFlow provides a powerful tool called TensorBoard for data visualization.\n",
    "\n",
    "To begin, we need to set up a data path for the TensorBoard callback to store the results:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "15e27db192652c62"
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "root_logdir = os.path.join(os.curdir, \"my_logs\")\n",
    "\n",
    "def get_run_logdir(id_for_run):\n",
    " return os.path.join(root_logdir, id_for_run)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-06T11:45:47.965752700Z",
     "start_time": "2024-04-06T11:45:46.062692800Z"
    }
   },
   "id": "68096613f5f7fd3f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "To optimize our model's performance, we can experiment with different values of the learning_rate parameter. After training with each value, we can visualize the results using TensorBoard, a powerful tool provided by TensorFlow for data visualization."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4008e59ebc09e195"
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001B[1m1407/1407\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m8s\u001B[0m 4ms/step - accuracy: 0.2419 - loss: 2.2027 - val_accuracy: 0.3624 - val_loss: 1.7958\n",
      "Epoch 2/10\n",
      "\u001B[1m1407/1407\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 4ms/step - accuracy: 0.3718 - loss: 1.7927 - val_accuracy: 0.4048 - val_loss: 1.6957\n",
      "Epoch 3/10\n",
      "\u001B[1m1407/1407\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 4ms/step - accuracy: 0.4061 - loss: 1.6928 - val_accuracy: 0.4194 - val_loss: 1.6450\n",
      "Epoch 4/10\n",
      "\u001B[1m1407/1407\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 4ms/step - accuracy: 0.4302 - loss: 1.6318 - val_accuracy: 0.4284 - val_loss: 1.6127\n",
      "Epoch 5/10\n",
      "\u001B[1m1407/1407\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 4ms/step - accuracy: 0.4456 - loss: 1.5868 - val_accuracy: 0.4362 - val_loss: 1.5868\n",
      "Epoch 6/10\n",
      "\u001B[1m1407/1407\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 4ms/step - accuracy: 0.4578 - loss: 1.5504 - val_accuracy: 0.4458 - val_loss: 1.5674\n",
      "Epoch 7/10\n",
      "\u001B[1m1407/1407\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 4ms/step - accuracy: 0.4692 - loss: 1.5196 - val_accuracy: 0.4536 - val_loss: 1.5514\n",
      "Epoch 8/10\n",
      "\u001B[1m1407/1407\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 4ms/step - accuracy: 0.4790 - loss: 1.4926 - val_accuracy: 0.4598 - val_loss: 1.5377\n",
      "Epoch 9/10\n",
      "\u001B[1m1407/1407\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 4ms/step - accuracy: 0.4867 - loss: 1.4687 - val_accuracy: 0.4642 - val_loss: 1.5269\n",
      "Epoch 10/10\n",
      "\u001B[1m1407/1407\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 4ms/step - accuracy: 0.4937 - loss: 1.4469 - val_accuracy: 0.4690 - val_loss: 1.5176\n",
      "Epoch 1/10\n",
      "\u001B[1m1407/1407\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m8s\u001B[0m 4ms/step - accuracy: 0.4904 - loss: 1.4468 - val_accuracy: 0.4742 - val_loss: 1.5062\n",
      "Epoch 2/10\n",
      "\u001B[1m1407/1407\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 4ms/step - accuracy: 0.5082 - loss: 1.4041 - val_accuracy: 0.4790 - val_loss: 1.4883\n",
      "Epoch 3/10\n",
      "\u001B[1m1407/1407\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 4ms/step - accuracy: 0.5210 - loss: 1.3650 - val_accuracy: 0.4844 - val_loss: 1.4760\n",
      "Epoch 4/10\n",
      "\u001B[1m1407/1407\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 4ms/step - accuracy: 0.5327 - loss: 1.3312 - val_accuracy: 0.4908 - val_loss: 1.4665\n",
      "Epoch 5/10\n",
      "\u001B[1m1407/1407\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 4ms/step - accuracy: 0.5435 - loss: 1.3007 - val_accuracy: 0.4900 - val_loss: 1.4586\n",
      "Epoch 6/10\n",
      "\u001B[1m1407/1407\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 4ms/step - accuracy: 0.5528 - loss: 1.2732 - val_accuracy: 0.4966 - val_loss: 1.4525\n",
      "Epoch 7/10\n",
      "\u001B[1m1407/1407\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 4ms/step - accuracy: 0.5630 - loss: 1.2473 - val_accuracy: 0.4980 - val_loss: 1.4480\n",
      "Epoch 8/10\n",
      "\u001B[1m1407/1407\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 4ms/step - accuracy: 0.5707 - loss: 1.2231 - val_accuracy: 0.4984 - val_loss: 1.4439\n",
      "Epoch 9/10\n",
      "\u001B[1m1407/1407\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 4ms/step - accuracy: 0.5793 - loss: 1.2011 - val_accuracy: 0.4996 - val_loss: 1.4424\n",
      "Epoch 10/10\n",
      "\u001B[1m1407/1407\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 4ms/step - accuracy: 0.5875 - loss: 1.1801 - val_accuracy: 0.5002 - val_loss: 1.4406\n",
      "Epoch 1/10\n",
      "\u001B[1m1407/1407\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 4ms/step - accuracy: 0.5615 - loss: 1.2519 - val_accuracy: 0.4886 - val_loss: 1.4616\n",
      "Epoch 2/10\n",
      "\u001B[1m1407/1407\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 4ms/step - accuracy: 0.5757 - loss: 1.2098 - val_accuracy: 0.4936 - val_loss: 1.4612\n",
      "Epoch 3/10\n",
      "\u001B[1m1407/1407\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 4ms/step - accuracy: 0.5917 - loss: 1.1672 - val_accuracy: 0.5002 - val_loss: 1.4569\n",
      "Epoch 4/10\n",
      "\u001B[1m1407/1407\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 4ms/step - accuracy: 0.6064 - loss: 1.1274 - val_accuracy: 0.5002 - val_loss: 1.4639\n",
      "Epoch 5/10\n",
      "\u001B[1m1407/1407\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 4ms/step - accuracy: 0.6213 - loss: 1.0917 - val_accuracy: 0.4984 - val_loss: 1.4719\n",
      "Epoch 6/10\n",
      "\u001B[1m1407/1407\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 4ms/step - accuracy: 0.6324 - loss: 1.0570 - val_accuracy: 0.4972 - val_loss: 1.4848\n",
      "Epoch 7/10\n",
      "\u001B[1m1407/1407\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 4ms/step - accuracy: 0.6451 - loss: 1.0244 - val_accuracy: 0.4980 - val_loss: 1.4980\n",
      "Epoch 8/10\n",
      "\u001B[1m1407/1407\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 4ms/step - accuracy: 0.6564 - loss: 0.9932 - val_accuracy: 0.4994 - val_loss: 1.5133\n",
      "Epoch 9/10\n",
      "\u001B[1m1407/1407\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 4ms/step - accuracy: 0.6686 - loss: 0.9619 - val_accuracy: 0.4980 - val_loss: 1.5329\n",
      "Epoch 10/10\n",
      "\u001B[1m1407/1407\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 4ms/step - accuracy: 0.6788 - loss: 0.9338 - val_accuracy: 0.4972 - val_loss: 1.5505\n",
      "Epoch 1/10\n",
      "\u001B[1m1407/1407\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 4ms/step - accuracy: 0.5942 - loss: 1.1461 - val_accuracy: 0.4922 - val_loss: 1.5453\n",
      "Epoch 2/10\n",
      "\u001B[1m1407/1407\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 4ms/step - accuracy: 0.6133 - loss: 1.0946 - val_accuracy: 0.4924 - val_loss: 1.5735\n",
      "Epoch 3/10\n",
      "\u001B[1m1407/1407\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 4ms/step - accuracy: 0.6321 - loss: 1.0523 - val_accuracy: 0.4846 - val_loss: 1.5872\n",
      "Epoch 4/10\n",
      "\u001B[1m1407/1407\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 4ms/step - accuracy: 0.6427 - loss: 1.0079 - val_accuracy: 0.4864 - val_loss: 1.6262\n",
      "Epoch 5/10\n",
      "\u001B[1m1407/1407\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 4ms/step - accuracy: 0.6591 - loss: 0.9684 - val_accuracy: 0.4878 - val_loss: 1.6577\n",
      "Epoch 6/10\n",
      "\u001B[1m1407/1407\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 4ms/step - accuracy: 0.6740 - loss: 0.9257 - val_accuracy: 0.4788 - val_loss: 1.6979\n",
      "Epoch 7/10\n",
      "\u001B[1m1407/1407\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 4ms/step - accuracy: 0.6906 - loss: 0.8789 - val_accuracy: 0.4804 - val_loss: 1.7445\n",
      "Epoch 8/10\n",
      "\u001B[1m1407/1407\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 4ms/step - accuracy: 0.7060 - loss: 0.8445 - val_accuracy: 0.4826 - val_loss: 1.7789\n",
      "Epoch 9/10\n",
      "\u001B[1m1407/1407\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 4ms/step - accuracy: 0.7181 - loss: 0.8047 - val_accuracy: 0.4850 - val_loss: 1.8108\n",
      "Epoch 10/10\n",
      "\u001B[1m1407/1407\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 4ms/step - accuracy: 0.7299 - loss: 0.7741 - val_accuracy: 0.4726 - val_loss: 1.9048\n",
      "Epoch 1/10\n",
      "\u001B[1m1407/1407\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 4ms/step - accuracy: 0.5313 - loss: 1.3914 - val_accuracy: 0.4530 - val_loss: 1.6150\n",
      "Epoch 2/10\n",
      "\u001B[1m1407/1407\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 4ms/step - accuracy: 0.5422 - loss: 1.2849 - val_accuracy: 0.4592 - val_loss: 1.5662\n",
      "Epoch 3/10\n",
      "\u001B[1m1407/1407\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 4ms/step - accuracy: 0.5546 - loss: 1.2417 - val_accuracy: 0.4780 - val_loss: 1.5254\n",
      "Epoch 4/10\n",
      "\u001B[1m1407/1407\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 4ms/step - accuracy: 0.5684 - loss: 1.2006 - val_accuracy: 0.4768 - val_loss: 1.5739\n",
      "Epoch 5/10\n",
      "\u001B[1m1407/1407\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 4ms/step - accuracy: 0.5874 - loss: 1.1642 - val_accuracy: 0.4900 - val_loss: 1.5444\n",
      "Epoch 6/10\n",
      "\u001B[1m1407/1407\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 4ms/step - accuracy: 0.6012 - loss: 1.1211 - val_accuracy: 0.4838 - val_loss: 1.5684\n",
      "Epoch 7/10\n",
      "\u001B[1m1407/1407\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 4ms/step - accuracy: 0.6176 - loss: 1.0752 - val_accuracy: 0.4904 - val_loss: 1.6009\n",
      "Epoch 8/10\n",
      "\u001B[1m1407/1407\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 4ms/step - accuracy: 0.6286 - loss: 1.0452 - val_accuracy: 0.4942 - val_loss: 1.5992\n",
      "Epoch 9/10\n",
      "\u001B[1m1407/1407\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 4ms/step - accuracy: 0.6389 - loss: 1.0174 - val_accuracy: 0.4918 - val_loss: 1.6264\n",
      "Epoch 10/10\n",
      "\u001B[1m1407/1407\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 4ms/step - accuracy: 0.6531 - loss: 0.9765 - val_accuracy: 0.4904 - val_loss: 1.6779\n",
      "Epoch 1/10\n",
      "\u001B[1m1407/1407\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 4ms/step - accuracy: 0.4886 - loss: 1.4576 - val_accuracy: 0.4274 - val_loss: 1.6490\n",
      "Epoch 2/10\n",
      "\u001B[1m1407/1407\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 4ms/step - accuracy: 0.4876 - loss: 1.4624 - val_accuracy: 0.4502 - val_loss: 1.6363\n",
      "Epoch 3/10\n",
      "\u001B[1m1407/1407\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 4ms/step - accuracy: 0.4997 - loss: 1.4179 - val_accuracy: 0.4628 - val_loss: 1.6052\n",
      "Epoch 4/10\n",
      "\u001B[1m1407/1407\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 4ms/step - accuracy: 0.5224 - loss: 1.3658 - val_accuracy: 0.4666 - val_loss: 1.6098\n",
      "Epoch 5/10\n",
      "\u001B[1m1407/1407\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 4ms/step - accuracy: 0.5311 - loss: 1.3369 - val_accuracy: 0.4842 - val_loss: 1.5372\n",
      "Epoch 6/10\n",
      "\u001B[1m1407/1407\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 4ms/step - accuracy: 0.5423 - loss: 1.3060 - val_accuracy: 0.4874 - val_loss: 1.5264\n",
      "Epoch 7/10\n",
      "\u001B[1m1407/1407\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 4ms/step - accuracy: 0.5502 - loss: 1.2892 - val_accuracy: 0.4922 - val_loss: 1.5544\n",
      "Epoch 8/10\n",
      "\u001B[1m1407/1407\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 4ms/step - accuracy: 0.5702 - loss: 1.2395 - val_accuracy: 0.4730 - val_loss: 1.5911\n",
      "Epoch 9/10\n",
      "\u001B[1m1407/1407\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 4ms/step - accuracy: 0.5773 - loss: 1.2204 - val_accuracy: 0.4894 - val_loss: 1.5788\n",
      "Epoch 10/10\n",
      "\u001B[1m1407/1407\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 4ms/step - accuracy: 0.5854 - loss: 1.1913 - val_accuracy: 0.4928 - val_loss: 1.5920\n",
      "Epoch 1/10\n",
      "\u001B[1m1407/1407\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 4ms/step - accuracy: 0.3007 - loss: 1.9991 - val_accuracy: 0.1038 - val_loss: 2.4808\n",
      "Epoch 2/10\n",
      "\u001B[1m1407/1407\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 4ms/step - accuracy: 0.0971 - loss: 2.3877 - val_accuracy: 0.1038 - val_loss: 2.5052\n",
      "Epoch 3/10\n",
      "\u001B[1m1407/1407\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 4ms/step - accuracy: 0.0977 - loss: 2.3915 - val_accuracy: 0.1038 - val_loss: 2.5150\n",
      "Epoch 4/10\n",
      "\u001B[1m1407/1407\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 4ms/step - accuracy: 0.0977 - loss: 2.3931 - val_accuracy: 0.1038 - val_loss: 2.5185\n",
      "Epoch 5/10\n",
      "\u001B[1m1407/1407\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 4ms/step - accuracy: 0.0977 - loss: 2.3937 - val_accuracy: 0.1038 - val_loss: 2.5195\n",
      "Epoch 6/10\n",
      "\u001B[1m1407/1407\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 4ms/step - accuracy: 0.0977 - loss: 2.3939 - val_accuracy: 0.1038 - val_loss: 2.5197\n",
      "Epoch 7/10\n",
      "\u001B[1m1407/1407\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 4ms/step - accuracy: 0.0976 - loss: 2.3940 - val_accuracy: 0.1038 - val_loss: 2.5198\n",
      "Epoch 8/10\n",
      "\u001B[1m1407/1407\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 4ms/step - accuracy: 0.0976 - loss: 2.3940 - val_accuracy: 0.1038 - val_loss: 2.5198\n",
      "Epoch 9/10\n",
      "\u001B[1m1407/1407\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 4ms/step - accuracy: 0.0976 - loss: 2.3940 - val_accuracy: 0.1038 - val_loss: 2.5198\n",
      "Epoch 10/10\n",
      "\u001B[1m1407/1407\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 4ms/step - accuracy: 0.0976 - loss: 2.3940 - val_accuracy: 0.1038 - val_loss: 2.5198\n"
     ]
    }
   ],
   "source": [
    "norm_layer = tf.keras.layers.Normalization()\n",
    "norm_layer.adapt(X_train)\n",
    "\n",
    "X_train_scaled = norm_layer(X_train)\n",
    "X_valid_scaled = norm_layer(X_valid)\n",
    "\n",
    "model = create_model()\n",
    "\n",
    "for i in [1e-5, 3e-5, 1e-4, 3e-4, 1e-3, 3e-3, 1e-2]:\n",
    "    optimizer = tf.keras.optimizers.Nadam(learning_rate=i)\n",
    "    model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=optimizer,\n",
    "              metrics=[\"accuracy\"])\n",
    "    tensorboard_cb = tf.keras.callbacks.TensorBoard(get_run_logdir(str(i)))\n",
    "    history = model.fit(X_train_scaled, y_train, epochs=10,\n",
    "                        validation_data=(X_valid_scaled, y_valid),\n",
    "                        callbacks=[tensorboard_cb])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-05T12:03:44.534518100Z",
     "start_time": "2024-04-05T11:57:11.725248400Z"
    }
   },
   "id": "da5df840cbf8274f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Evaluating Learning Rate Performance:\n",
    "\n",
    "Default learning rate: 1e-4, resulted in the best performance based on the plotted metrics in TensorBoard.\n",
    "\n",
    "## Exploring Learning Rate Scheduling:\n",
    "\n",
    "Learning Rate Scheduling offers a dynamic approach to adjusting the learning rate during training. This technique allows the model to adapt and fine-tune its learning rate over time, potentially leading to improved convergence and performance on the dataset. There are many scheduling algorithms, like:\n",
    " - Power scheduling\n",
    " - Exponential scheduling\n",
    " - Piecewise constant scheduling\n",
    " - Performance scheduling\n",
    "\n",
    "# Implementing Performance Scheduling Algorithm with ReduceLROnPlateau Callback\n",
    "\n",
    "For this task, the Performance Scheduling algorithm is the chosen method for dynamically adjusting the learning rate during training. This algorithm evaluates the validation error every N steps, reducing the learning rate if the error fails to decrease for N consecutive steps.\n",
    "\n",
    "## Utilizing ReduceLROnPlateau Callback:\n",
    "\n",
    "Implementing Performance Scheduling in Keras is straightforward with the ReduceLROnPlateau callback. While there are two variants of this callback—one reduces the learning rate every N epochs, and the other reduces it every N steps—we will adopt the former approach for this task.\n",
    "\n",
    "## Defining full set of callbacks\n",
    "\n",
    "- Early Stopping callback to prevent overfitting\n",
    "- TensorBoard callback to visualize data\n",
    "- ModelCheckpoint callback to save the model when its performance on the validation set is the best so far (save_best_only=True must be set)\n",
    "- ReduceLROnPlateau callback to reach a good solution faster than with the optimal constant learning rate\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6f51f6a1e113c4eb"
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "root_log_dir = os.path.join(os.curdir, \"my_logs_train\")\n",
    "\n",
    "def get_run_logdir():\n",
    "    import time\n",
    "    run_id = time.strftime(\"run_%Y_%m_%d-%H_%M_%S\")\n",
    "    return os.path.join(root_log_dir, run_id)\n",
    "\n",
    "log_dir = get_run_logdir()\n",
    "tensorboard_cb = tf.keras.callbacks.TensorBoard(log_dir=log_dir)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-06T11:59:22.516545700Z",
     "start_time": "2024-04-06T11:59:22.490514Z"
    }
   },
   "id": "ad505913aa659a7c"
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "early_stopping_cb = tf.keras.callbacks.EarlyStopping(patience=6, monitor=\"val_loss\", mode='min')\n",
    "lr_scheduler_cb = tf.keras.callbacks.ReduceLROnPlateau(factor=0.5, patience=3)\n",
    "checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(\"my_cifar10_model_v1.keras\", save_best_only=True)\n",
    "callbacks = [early_stopping_cb, checkpoint_cb, tensorboard_cb, lr_scheduler_cb]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-06T11:59:26.279430200Z",
     "start_time": "2024-04-06T11:59:26.260432500Z"
    }
   },
   "id": "63a208bbcaebc46a"
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001B[1m1407/1407\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m8s\u001B[0m 4ms/step - accuracy: 0.3332 - loss: 1.9311 - val_accuracy: 0.4328 - val_loss: 1.6049 - learning_rate: 1.0000e-04\n",
      "Epoch 2/100\n",
      "\u001B[1m1407/1407\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 4ms/step - accuracy: 0.4513 - loss: 1.5532 - val_accuracy: 0.4598 - val_loss: 1.5319 - learning_rate: 1.0000e-04\n",
      "Epoch 3/100\n",
      "\u001B[1m1407/1407\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 4ms/step - accuracy: 0.4952 - loss: 1.4375 - val_accuracy: 0.4734 - val_loss: 1.4960 - learning_rate: 1.0000e-04\n",
      "Epoch 4/100\n",
      "\u001B[1m1407/1407\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 4ms/step - accuracy: 0.5212 - loss: 1.3562 - val_accuracy: 0.4856 - val_loss: 1.4711 - learning_rate: 1.0000e-04\n",
      "Epoch 5/100\n",
      "\u001B[1m1407/1407\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 4ms/step - accuracy: 0.5445 - loss: 1.2929 - val_accuracy: 0.4868 - val_loss: 1.4573 - learning_rate: 1.0000e-04\n",
      "Epoch 6/100\n",
      "\u001B[1m1407/1407\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 4ms/step - accuracy: 0.5632 - loss: 1.2388 - val_accuracy: 0.4932 - val_loss: 1.4534 - learning_rate: 1.0000e-04\n",
      "Epoch 7/100\n",
      "\u001B[1m1407/1407\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 4ms/step - accuracy: 0.5816 - loss: 1.1919 - val_accuracy: 0.4978 - val_loss: 1.4575 - learning_rate: 1.0000e-04\n",
      "Epoch 8/100\n",
      "\u001B[1m1407/1407\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m11s\u001B[0m 8ms/step - accuracy: 0.5984 - loss: 1.1476 - val_accuracy: 0.5022 - val_loss: 1.4635 - learning_rate: 1.0000e-04\n",
      "Epoch 9/100\n",
      "\u001B[1m1407/1407\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m9s\u001B[0m 6ms/step - accuracy: 0.6135 - loss: 1.1077 - val_accuracy: 0.5032 - val_loss: 1.4711 - learning_rate: 1.0000e-04\n",
      "Epoch 10/100\n",
      "\u001B[1m1407/1407\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 4ms/step - accuracy: 0.6363 - loss: 1.0478 - val_accuracy: 0.5092 - val_loss: 1.4404 - learning_rate: 5.0000e-05\n",
      "Epoch 11/100\n",
      "\u001B[1m1407/1407\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 4ms/step - accuracy: 0.6508 - loss: 1.0115 - val_accuracy: 0.5080 - val_loss: 1.4498 - learning_rate: 5.0000e-05\n",
      "Epoch 12/100\n",
      "\u001B[1m1407/1407\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 4ms/step - accuracy: 0.6586 - loss: 0.9868 - val_accuracy: 0.5124 - val_loss: 1.4585 - learning_rate: 5.0000e-05\n",
      "Epoch 13/100\n",
      "\u001B[1m1407/1407\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 5ms/step - accuracy: 0.6685 - loss: 0.9647 - val_accuracy: 0.5108 - val_loss: 1.4689 - learning_rate: 5.0000e-05\n",
      "Epoch 14/100\n",
      "\u001B[1m1407/1407\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 4ms/step - accuracy: 0.6776 - loss: 0.9378 - val_accuracy: 0.5118 - val_loss: 1.4556 - learning_rate: 2.5000e-05\n",
      "Epoch 15/100\n",
      "\u001B[1m1407/1407\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 4ms/step - accuracy: 0.6866 - loss: 0.9175 - val_accuracy: 0.5146 - val_loss: 1.4634 - learning_rate: 2.5000e-05\n",
      "Epoch 16/100\n",
      "\u001B[1m1407/1407\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 4ms/step - accuracy: 0.6910 - loss: 0.9038 - val_accuracy: 0.5142 - val_loss: 1.4711 - learning_rate: 2.5000e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.src.callbacks.history.History at 0x2a3527c4310>"
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = create_model()\n",
    "optimizer = tf.keras.optimizers.Nadam(learning_rate=1e-4)\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=optimizer,\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "model.fit(X_train_scaled, y_train, epochs=100,\n",
    "          validation_data=(X_valid_scaled, y_valid),\n",
    "          callbacks=callbacks)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-05T13:19:58.329368900Z",
     "start_time": "2024-04-05T13:18:15.918159Z"
    }
   },
   "id": "afc4fc73e07d6f04"
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m157/157\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step - accuracy: 0.5115 - loss: 1.4395\n"
     ]
    },
    {
     "data": {
      "text/plain": "[1.440427541732788, 0.5091999769210815]"
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = tf.keras.models.load_model(\"my_cifar10_model_v1.keras\")\n",
    "model.evaluate(X_valid_scaled, y_valid)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-05T13:19:59.064953300Z",
     "start_time": "2024-04-05T13:19:58.314371700Z"
    }
   },
   "id": "848c014c37c4adc9"
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m1407/1407\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 1ms/step - accuracy: 0.6457 - loss: 1.0136\n"
     ]
    },
    {
     "data": {
      "text/plain": "[1.0154922008514404, 0.6470444202423096]"
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_train_scaled, y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-05T13:20:01.105373Z",
     "start_time": "2024-04-05T13:19:59.062960200Z"
    }
   },
   "id": "801dc730a3554368"
  },
  {
   "cell_type": "markdown",
   "source": [
    "It took us only 11 epochs to reach this result, after the 11th epoch model's there was no significant increase in validation accuracy, whereas training accuracy kept increasing, meaning that the model started to overfit the data significantly. We can try building new neural network, but now using ELU activation function together with BatchNormalization and whether it works better or not."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c06c9d3d0c4648ee"
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "model_bn = tf.keras.models.Sequential()\n",
    "\n",
    "model_bn.add(tf.keras.layers.Flatten(input_shape=[32, 32, 3]))\n",
    "model_bn.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "for _ in range(5):\n",
    "    model_bn.add(tf.keras.layers.Dense(100,\n",
    "                                 kernel_initializer=\"he_normal\",\n",
    "                                 kernel_constraint=tf.keras.constraints.max_norm(1.)))\n",
    "    model_bn.add(tf.keras.layers.BatchNormalization())\n",
    "    model_bn.add(tf.keras.layers.Activation(\"elu\"))\n",
    "model_bn.add(tf.keras.layers.Dense(10, activation=\"softmax\"))\n",
    "\n",
    "optimizer = tf.keras.optimizers.Nadam(learning_rate=1e-3)\n",
    "model_bn.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=optimizer,\n",
    "              metrics=[\"accuracy\"])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-06T12:07:51.400901600Z",
     "start_time": "2024-04-06T12:07:51.204756Z"
    }
   },
   "id": "13c5992cf8d61a8c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can set learning rate to 0.001, since we are using Performance scheduling."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "aff0844ee909e097"
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "early_stopping_cb = tf.keras.callbacks.EarlyStopping(patience=6, monitor=\"val_loss\")\n",
    "lr_scheduler_cb = tf.keras.callbacks.ReduceLROnPlateau(factor=0.5, patience=3)\n",
    "checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(\"my_cifar10_model_bn_v1.keras\", save_best_only=True)\n",
    "callbacks = [early_stopping_cb, checkpoint_cb, tensorboard_cb, lr_scheduler_cb]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-06T12:07:52.624384700Z",
     "start_time": "2024-04-06T12:07:52.605850200Z"
    }
   },
   "id": "a4fa553c3bdeab99"
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001B[1m1407/1407\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 6ms/step - accuracy: 0.3550 - loss: 1.8220 - val_accuracy: 0.4190 - val_loss: 1.6278 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "\u001B[1m1407/1407\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m8s\u001B[0m 5ms/step - accuracy: 0.4234 - loss: 1.6046 - val_accuracy: 0.4418 - val_loss: 1.5864 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "\u001B[1m1407/1407\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m8s\u001B[0m 5ms/step - accuracy: 0.4411 - loss: 1.5666 - val_accuracy: 0.4348 - val_loss: 1.5744 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "\u001B[1m1407/1407\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 7ms/step - accuracy: 0.4482 - loss: 1.5412 - val_accuracy: 0.4432 - val_loss: 1.5606 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "\u001B[1m1407/1407\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m22s\u001B[0m 15ms/step - accuracy: 0.4577 - loss: 1.5186 - val_accuracy: 0.4568 - val_loss: 1.5380 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "\u001B[1m1407/1407\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m40s\u001B[0m 14ms/step - accuracy: 0.4641 - loss: 1.4992 - val_accuracy: 0.4606 - val_loss: 1.5259 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "\u001B[1m1407/1407\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m22s\u001B[0m 16ms/step - accuracy: 0.4696 - loss: 1.4840 - val_accuracy: 0.4618 - val_loss: 1.5258 - learning_rate: 0.0010\n",
      "Epoch 8/100\n",
      "\u001B[1m1407/1407\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m21s\u001B[0m 15ms/step - accuracy: 0.4750 - loss: 1.4705 - val_accuracy: 0.4618 - val_loss: 1.5244 - learning_rate: 0.0010\n",
      "Epoch 9/100\n",
      "\u001B[1m1407/1407\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m21s\u001B[0m 15ms/step - accuracy: 0.4774 - loss: 1.4629 - val_accuracy: 0.4666 - val_loss: 1.5162 - learning_rate: 0.0010\n",
      "Epoch 10/100\n",
      "\u001B[1m1407/1407\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 7ms/step - accuracy: 0.4822 - loss: 1.4503 - val_accuracy: 0.4730 - val_loss: 1.5070 - learning_rate: 0.0010\n",
      "Epoch 11/100\n",
      "\u001B[1m1407/1407\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m8s\u001B[0m 5ms/step - accuracy: 0.4888 - loss: 1.4384 - val_accuracy: 0.4712 - val_loss: 1.4942 - learning_rate: 0.0010\n",
      "Epoch 12/100\n",
      "\u001B[1m1407/1407\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 5ms/step - accuracy: 0.4888 - loss: 1.4289 - val_accuracy: 0.4628 - val_loss: 1.5102 - learning_rate: 0.0010\n",
      "Epoch 13/100\n",
      "\u001B[1m1407/1407\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 5ms/step - accuracy: 0.4909 - loss: 1.4213 - val_accuracy: 0.4648 - val_loss: 1.5160 - learning_rate: 0.0010\n",
      "Epoch 14/100\n",
      "\u001B[1m1407/1407\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m8s\u001B[0m 6ms/step - accuracy: 0.4940 - loss: 1.4148 - val_accuracy: 0.4650 - val_loss: 1.5221 - learning_rate: 0.0010\n",
      "Epoch 15/100\n",
      "\u001B[1m1407/1407\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 5ms/step - accuracy: 0.5223 - loss: 1.3338 - val_accuracy: 0.4940 - val_loss: 1.4262 - learning_rate: 5.0000e-04\n",
      "Epoch 16/100\n",
      "\u001B[1m1407/1407\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m8s\u001B[0m 5ms/step - accuracy: 0.5425 - loss: 1.2828 - val_accuracy: 0.4938 - val_loss: 1.4309 - learning_rate: 5.0000e-04\n",
      "Epoch 17/100\n",
      "\u001B[1m1407/1407\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 5ms/step - accuracy: 0.5521 - loss: 1.2540 - val_accuracy: 0.4910 - val_loss: 1.4355 - learning_rate: 5.0000e-04\n",
      "Epoch 18/100\n",
      "\u001B[1m1407/1407\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 5ms/step - accuracy: 0.5599 - loss: 1.2322 - val_accuracy: 0.4936 - val_loss: 1.4391 - learning_rate: 5.0000e-04\n",
      "Epoch 19/100\n",
      "\u001B[1m1407/1407\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m8s\u001B[0m 6ms/step - accuracy: 0.5863 - loss: 1.1663 - val_accuracy: 0.5060 - val_loss: 1.4019 - learning_rate: 2.5000e-04\n",
      "Epoch 20/100\n",
      "\u001B[1m1407/1407\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m8s\u001B[0m 5ms/step - accuracy: 0.6052 - loss: 1.1141 - val_accuracy: 0.5062 - val_loss: 1.4207 - learning_rate: 2.5000e-04\n",
      "Epoch 21/100\n",
      "\u001B[1m1407/1407\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m8s\u001B[0m 5ms/step - accuracy: 0.6176 - loss: 1.0788 - val_accuracy: 0.5028 - val_loss: 1.4437 - learning_rate: 2.5000e-04\n",
      "Epoch 22/100\n",
      "\u001B[1m1407/1407\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m8s\u001B[0m 5ms/step - accuracy: 0.6290 - loss: 1.0487 - val_accuracy: 0.5014 - val_loss: 1.4679 - learning_rate: 2.5000e-04\n",
      "Epoch 23/100\n",
      "\u001B[1m1407/1407\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m8s\u001B[0m 5ms/step - accuracy: 0.6459 - loss: 0.9970 - val_accuracy: 0.5138 - val_loss: 1.4313 - learning_rate: 1.2500e-04\n",
      "Epoch 24/100\n",
      "\u001B[1m1407/1407\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 5ms/step - accuracy: 0.6645 - loss: 0.9498 - val_accuracy: 0.5124 - val_loss: 1.4581 - learning_rate: 1.2500e-04\n",
      "Epoch 25/100\n",
      "\u001B[1m1407/1407\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 5ms/step - accuracy: 0.6774 - loss: 0.9166 - val_accuracy: 0.5114 - val_loss: 1.4861 - learning_rate: 1.2500e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.src.callbacks.history.History at 0x1f34edf2c10>"
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_bn.fit(X_train_scaled, y_train, epochs=100,\n",
    "          validation_data=(X_valid_scaled, y_valid),\n",
    "          callbacks=callbacks)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-06T12:12:40.445289500Z",
     "start_time": "2024-04-06T12:07:53.280219600Z"
    }
   },
   "id": "16fd332369a7c2ff"
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m157/157\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 2ms/step - accuracy: 0.5033 - loss: 1.4019\n"
     ]
    },
    {
     "data": {
      "text/plain": "[1.4019014835357666, 0.5059999823570251]"
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_bn = tf.keras.models.load_model(\"my_cifar10_model_bn_v1.keras\")\n",
    "model_bn.evaluate(X_valid_scaled, y_valid)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-06T12:12:41.480786200Z",
     "start_time": "2024-04-06T12:12:40.447290600Z"
    }
   },
   "id": "9ad5361e50381482"
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m1407/1407\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 1ms/step - accuracy: 0.5819 - loss: 1.1800\n"
     ]
    },
    {
     "data": {
      "text/plain": "[1.1776326894760132, 0.5823333263397217]"
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_bn.evaluate(X_train_scaled, y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-06T12:12:43.366661100Z",
     "start_time": "2024-04-06T12:12:41.483795700Z"
    }
   },
   "id": "78c6103035b54c01"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Conclusion\n",
    "\n",
    "After training and evaluating the second model, we can conclude the following:\n",
    "\n",
    "- **Validation Accuracy**: There was no significant difference in validation accuracy between the two models. Both models performed similarly in terms of predicting on unseen data.\n",
    "\n",
    "- **Gap Between Validation and Training Accuracies**: The second model exhibited a much smaller gap between validation and training accuracies compared to the first model. This suggests that the second model may have better generalization performance and could benefit from further tuning.\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "We can further explore and fine-tune the parameters of the second model to enhance its performance. Potential steps include:\n",
    "- Hyperparameter tuning: Experiment with different learning rates, batch sizes, and optimizer configurations.\n",
    "- Regularization techniques: Apply dropout, L1/L2 regularization, or other regularization methods to prevent overfitting (other than Max_norm regularization).\n",
    "- Model architecture modifications: Adjust the number of layers, units per layer, or try alternative activation functions to improve performance.\n",
    "\n",
    "Overall, the findings suggest that the second model shows promise and warrants further investigation to unlock its full potential.\n",
    " "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "59c2b900fe2ab2c2"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Fine-tuning becomes an easy job, when it comes to Keras Tuning library. We need to build a class that will have two methods: build() and fit(), build should return a model with new hyperparameters entered and fit is used to fit the model, but we can utilize it to decide how to preprocess the data or tweak batch size, and so on, based on hyperparameters passed to it. "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a247d38d85179288"
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [],
   "source": [
    "X_train = X_train_full[5000:]\n",
    "y_train = y_train_full[5000:]\n",
    "X_valid = X_train_full[:5000]\n",
    "y_valid = y_train_full[:5000]\n",
    "\n",
    "norm_layer = tf.keras.layers.Normalization()\n",
    "norm_layer.adapt(X_train)\n",
    "\n",
    "X_train_scaled = norm_layer(X_train)\n",
    "X_valid_scaled = norm_layer(X_valid)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-06T12:16:38.819676700Z",
     "start_time": "2024-04-06T12:16:35.702269300Z"
    }
   },
   "id": "e51842b6db9adac6"
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [
    "import keras_tuner as kt\n",
    "\n",
    "def build_model(hp):\n",
    "        n_hidden = hp.Int(\"n_hidden\", default=5, min_value=1, max_value=10)\n",
    "        n_neurons = hp.Int(\"n_neurons\", default=100, min_value=64, max_value=256)\n",
    "        learning_rate = hp.Float(\"learning_rate\", min_value=1e-5, max_value=1e-3)\n",
    "        \n",
    "        model_bn = tf.keras.models.Sequential()\n",
    "\n",
    "        model_bn.add(tf.keras.layers.Flatten(input_shape=[32, 32, 3]))\n",
    "        model_bn.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "        for _ in range(n_hidden):\n",
    "            model_bn.add(tf.keras.layers.Dense(n_neurons,\n",
    "                                 kernel_initializer=\"he_normal\",\n",
    "                                 kernel_constraint=tf.keras.constraints.max_norm(1.)))\n",
    "            model_bn.add(tf.keras.layers.BatchNormalization())\n",
    "            model_bn.add(tf.keras.layers.Activation(\"elu\"))\n",
    "            \n",
    "        model_bn.add(tf.keras.layers.Dense(10, activation=\"softmax\"))\n",
    "\n",
    "        optimizer = tf.keras.optimizers.Nadam(learning_rate=learning_rate)\n",
    "        model_bn.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=optimizer,\n",
    "              metrics=[\"accuracy\"])\n",
    "        return model_bn"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-06T12:17:02.618873300Z",
     "start_time": "2024-04-06T12:17:02.601359400Z"
    }
   },
   "id": "699954f81088ca42"
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 10 Complete [00h 01m 48s]\n",
      "val_accuracy: 0.5180000066757202\n",
      "\n",
      "Best val_accuracy So Far: 0.5198000073432922\n",
      "Total elapsed time: 00h 13m 48s\n"
     ]
    }
   ],
   "source": [
    "early_stopping_cb = tf.keras.callbacks.EarlyStopping(patience=6, monitor=\"val_loss\")\n",
    "lr_scheduler_cb = tf.keras.callbacks.ReduceLROnPlateau(factor=0.5, patience=3)\n",
    "callbacks = [early_stopping_cb, lr_scheduler_cb]\n",
    "\n",
    "bayesian_tuner = kt.BayesianOptimization(\n",
    "    build_model, objective=\"val_accuracy\", max_trials=10,\n",
    "    alpha=1e-4, beta=2.6, seed=42, directory=\"randomtuning\",\n",
    "    project_name=\"cifar10_usingDNN\", overwrite=True\n",
    ")\n",
    "bayesian_tuner.search(X_train_scaled, y_train, epochs=10,\n",
    "                      validation_data=(X_valid_scaled, y_valid),\n",
    "                      callbacks=callbacks)    "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1fcf389d1ca31885"
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m1407/1407\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 2ms/step - accuracy: 0.6308 - loss: 1.0289\n"
     ]
    },
    {
     "data": {
      "text/plain": "[1.0325251817703247, 0.6324666738510132]"
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model = bayesian_tuner.get_best_models(num_models=1)[0]\n",
    "best_model.evaluate(X_train_scaled, y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-06T12:52:23.919991900Z",
     "start_time": "2024-04-06T12:52:20.241361700Z"
    }
   },
   "id": "eced78b483a31a4c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Exploring Basic Fine-Tuning\n",
    "\n",
    "In this section, we delve into the results of basic fine-tuning, focusing on fundamental DNN architectures without extensive optimization. The objective here is to gain insights into working with simple DNNs and understanding popular real-world architectures.\n",
    "\n",
    "### Initial Results\n",
    "\n",
    "The initial fine-tuning results are summarized below:\n",
    "\n",
    "- *Accuracy*: The accuracy achieved with basic fine-tuning serves as a baseline for further exploration.\n",
    "- *Optimizer Selection*: No optimization regarding the choice of optimizer, max norm regularization value, batch size, etc., has been performed yet. This allows us to grasp the essence of DNN architectures without delving into intricate optimization strategies.\n",
    "\n",
    "### Conclusion\n",
    "\n",
    "Through basic fine-tuning, we have gained valuable insights into working with simple DNN architectures. Moving forward, we will explore optimization strategies and delve deeper into enhancing model performance while considering the need for lightning-fast response in certain scenarios.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7185e7d890670a18"
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m313/313\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 2ms/step - accuracy: 0.5150 - loss: 1.4133\n"
     ]
    },
    {
     "data": {
      "text/plain": "[1.4172695875167847, 0.5113000273704529]"
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_scaled = norm_layer(X_test)\n",
    "best_model.evaluate(X_test_scaled, y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-06T12:55:25.723374700Z",
     "start_time": "2024-04-06T12:55:24.821183800Z"
    }
   },
   "id": "dbb895db32a1b478"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Different thoughts on what can be explored further (Considerations for Lightning-Fast Response)\n",
    "\n",
    "While my primary focus has been on  finding the best architecture for this problem and basic fine-tuning, I acknowledge the importance of lightning-fast response in certain applications. Here are some considerations for achieving rapid predictions:\n",
    "\n",
    "- *Activation Functions*: ReLU or Leaky ReLU can be preferred over SeLU for faster response times, especially in self-normalizing models.\n",
    "- *Sparse Models*: Implementing sparse models, possibly using l1 regularization, can aid in achieving rapid predictions. However, this requires adjustments such as replacing SeLU with ReLU, normalization through BatchNormalization, among others."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8ca3c848e2343966"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
